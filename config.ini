[hyperparameters]
learning_rate = 2e-5
epsilon = 1e-8
beta1 = 0.9
beta2 = 0.999
weight_decay = 0.0
correct_bias = True
epochs = 4
batch_size = 32

[locations]
dataset_location = data
preprocessed_data_location = preprocessed_data
saved_model_location = saved-model

[dataset_labels]
contradiction = 0
entailment = 1
neutral = 2

[misc]
grad_clip_value = 1.0
batch_print_freq = 200
max_len_tokens = 128
seed_value = 42